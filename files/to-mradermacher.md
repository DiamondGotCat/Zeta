After the release of Llama 2, I realized for the first time that organizations other than OpenAI were also developing large language models (LLMs).
Although the chances of me building one myself were low, I knew I wouldn’t understand anything unless I gave it a try.
It all started when I had no programming knowledge whatsoever.

At that time, I asked ChatGPT a particular question, despite not using it much:
"Write code to build an LLM using information from Wikipedia."
Of course, ChatGPT back then couldn't generate such advanced code.
For about three months after that, I had completely forgotten about the challenge.

It was just before the release of Gemma.
The desire to create an LLM still lingered somewhere inside me, so I started working on it again.
At first, with the help of ChatGPT and using libraries like Transformers, I created my first self-made LLM, "Azuki.ai."
Of course, the responses weren't great, but at its best, it could at least respond to something like “hello.”

Some time passed after that,
and I wanted to create a more accurate LLM, so I launched the HINODE AI project.
This one was able to generate better responses, though still just at a toy level.
However, as I made improvements, the responses gradually got better.
It was during a break that something happened.

While browsing the Hinode-AI-0.1 page on Hugging Face, I noticed there was a quantized model available.
That was how I came to know about you, mradermacher.
Until then, I hadn’t thought very positively about my own activities.

Later, I launched the Zeta Project.
Shortly after releasing Zeta 1, I saw another example of conversion to GGUF format.
That became a turning point—I gained a bit more confidence and started becoming more active.

Eventually, I succeeded in creating its successor, Zeta 2.
I tried converting it to GGUF, but failed due to GPU-related issues, and that’s when a name suddenly came to mind:
“mradermacher.”
I immediately requested a conversion, and before long, I received a notification:
"It's queued! :D"

Even now, I continue to work on the Zeta project.
Zeta is supported by many kind people.
